{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------\n",
    "Questions to Martin (or to Martin's article):\n",
    "----------\n",
    "\n",
    "1. Before I could do convolutions and maxpoolings of 7 with stride 3 with inputs of 14x30, but now there is just 30. Should I try different filter sizes or is there one already predefined?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Here we go...\n",
    "import dataWindows as data\n",
    "from tensorflow.python.framework import ops\n",
    "ops.reset_default_graph()\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import math\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "To do here\n",
    "------------\n",
    "Fix the way the labels are being given since, they were working eg... to give result 5 (0 0 0 0 1 0 0 0 0 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(89, 1)\n"
     ]
    }
   ],
   "source": [
    "#Directories of the data\n",
    "data_dir = '/media/data/gomez/Padded_data_Sub_Jhmdb/Cut_each_3(Martins_experiment)/windows/windows_data1.mat'\n",
    "label_dir = '/media/data/gomez/Padded_data_Sub_Jhmdb/Cut_each_3(Martins_experiment)/windows/windows_labls1.mat'\n",
    "data_,labels_ = data.loadAll(data_dir,label_dir)\n",
    "\n",
    "train_data = data_['trainD']\n",
    "test_data_max = data_['testMax']\n",
    "test_data_avg = data_['testAvg']\n",
    "train_labels = labels_['trainL']\n",
    "test_labels = labels_['testL']\n",
    "\n",
    "print(test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a passed test\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "'''print(train_data[0])\n",
    "print(train_labels[0])'''\n",
    "print('a passed test')\n",
    "print(type(train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Parameters of training and viewing probabilities of the \n",
    "training_epochs = 10\n",
    "drop_out_prob = 0.5\n",
    "display_step = 10\n",
    "iterations = 20000\n",
    "learning_rate = 0.000001\n",
    "tb_logs_path = '/home/gomez/Documents/Thesis_doc/tb_net_result_windows'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of the data 30 shape of the labels 1 size of the train 2795 2795\n"
     ]
    }
   ],
   "source": [
    "train_size,shpeData = train_data.shape\n",
    "_,shpeLabl = train_labels.shape\n",
    "print('shape of the data', shpeData, 'shape of the labels', shpeLabl, 'size of the train',train_size,_)\n",
    "'''batch_size,shpeData = dataTest.shape\n",
    "_,shpeLabl = labelsTest.shape\n",
    "print('test',shpeData,shpeLabl,batch_size,_)'''\n",
    "\n",
    "#Modify the data according to the given shape above\n",
    "with tf.name_scope('input'):\n",
    "    batch_size = tf.placeholder(tf.int32)\n",
    "    x = tf.placeholder(tf.float32,[None,shpeData]) #[batch_size, shape_data_training_data]\n",
    "    y_ = tf.placeholder(tf.float32,[None,shpeLabl]) #[batch_size]     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Weight initialization\n",
    "\n",
    "def weight_variable(shape, name, var_type): #Change the type in order to specify the variable to use\n",
    "    with tf.name_scope('weight_' + name):\n",
    "        initial = tf.random_uniform(shape)\n",
    "        if(var_type == 'normal'):\n",
    "            initial = tf.random_normal(shape, stddev=0.1)\n",
    "        elif(var_type == 'trunc'): #As seen in the beginning\n",
    "            initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "        w_variable = tf.Variable(initial)\n",
    "        #tf.scalar_summary('_weight_' + name, w_variable)\n",
    "    return w_variable\n",
    "\n",
    "def bias_variable(shape, name):\n",
    "    with tf.name_scope('bias_' + name):\n",
    "        initial = tf.constant(0.1, shape=shape)\n",
    "        b_variable = tf.Variable(initial)\n",
    "        #tf.scalar_summary('_bias_' + name,b_variable)\n",
    "    return b_variable\n",
    "\n",
    "#Convolution and pooling (Martin: stride 30 for convolution, article: max_pooling of 7 with stride 7)\n",
    "\n",
    "'''Change in the convolution from 30 to 3 (since size of input = 30) stride remains equal'''\n",
    "def conv1d(x,w):\n",
    "    with tf.name_scope('Conv1d'):\n",
    "        convolution = tf.nn.conv1d(x,w,stride=3, padding='SAME')\n",
    "        #tf.scalar_summary('_Conv1d_',convolution)\n",
    "    return convolution\n",
    "\n",
    "'''Change in the convolution from 7 to 3 (since size of input = 30)'''\n",
    "def max_pool_3(x):    \n",
    "    with tf.name_scope('max_pool_stride3'):\n",
    "        max_pool7 = tf.nn.max_pool(x,ksize=[1,1,3,1],strides=[1,1,3,1], padding='SAME') #There is just max_pool in 2d and 3d so reshape and reshape\n",
    "        #tf.scalar_summary('_max_pool_stride7_',max_pool7)\n",
    "    return max_pool7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "-----------\n",
    "Remarks of this new version\n",
    "-----------\n",
    "\n",
    "w_conv1: changed to be a filter of size 30 to a filter of size 3 but same output to 32 \n",
    "h_conv1_4d: Changed to have from a filter of 30 to 3, so the shpeDate/30 will be also modified to shpeDate/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Relu:0\", shape=(1, 10, 32), dtype=float32)\n",
      "Tensor(\"max_pool_stride3/MaxPool:0\", shape=(1, 1, 4, 32), dtype=float32)\n",
      "Tensor(\"Reshape_2:0\", shape=(1, 4, 32), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "#First Layer\n",
    "\n",
    "w_conv1 = weight_variable([3,1,32], 'conv1', 'trunc') #Kernel size of 3 and from 1 input to 32 neurons\n",
    "b_conv1 = bias_variable([32], 'conv1') #32 biases going to different neurons\n",
    "\n",
    "x_data = tf.reshape(x, [1,shpeData,1]) #Image converted in 3d\n",
    "\n",
    "h_conv1 = tf.nn.relu(conv1d(x_data, w_conv1) + b_conv1)\n",
    "\n",
    "print(h_conv1)\n",
    "\n",
    "'''data: [3d] -> maxpooling(data): [4d] -> reconversion: [3d]'''\n",
    "\n",
    "# h_conv1_4d:[batch_size,1 (1d data), 28 (840/30 = after convolution 30 (filter and stride) ), 32 (the output to the new network)]\n",
    "\n",
    "'''From here, data becomes into a linnear value'''\n",
    "\n",
    "h_conv1_4d = tf.reshape(h_conv1,[1,1,-1,32]) #Check at this change made here (Before I converted everything to linnear, now it remains same as input)\n",
    "\n",
    "h_pool1 = max_pool_3(h_conv1_4d)\n",
    "\n",
    "print(h_pool1)\n",
    "\n",
    "#2 rshp_h_pool1:[batch_size, , 32 (output network)]\n",
    "\n",
    "rshp_h_pool1 = tf.reshape(h_pool1,[1,-1,32]) #shape\n",
    "print(rshp_h_pool1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Reshape_3:0\", shape=(1, 128), dtype=float32)\n",
      "Tensor(\"Relu_1:0\", shape=(1, 64), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "#Fully Connected layer 1\n",
    "\n",
    "W_fc1 = weight_variable([4*32,64], 'fc1','trunc') #weights converted from the dimensions\n",
    "b_fc1 = bias_variable([64], 'fc1')\n",
    "\n",
    "h_pool2_flat = tf.reshape(rshp_h_pool1, [-1, 4*32])\n",
    "print(h_pool2_flat)\n",
    "h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat,W_fc1)+b_fc1)\n",
    "print(h_fc1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Relu_2:0\", shape=(1, 128), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "#Fully Connected layer 2\n",
    "\n",
    "W_fc2 = weight_variable([64,128], 'fc2', 'trunc') #weights converted to   --> Modified from [128,256] to [64,128]\n",
    "b_fc2 = bias_variable([128], 'fc2') #Bias values going to the neurons\n",
    "\n",
    "h_fc2 = tf.nn.relu(tf.matmul(h_fc1,W_fc2)+b_fc2) #Relu #2 -> Check if this was right -> Should be (before the h_pool2 was)\n",
    "print(h_fc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"dropout/mul_1:0\", shape=(1, 128), dtype=float32)\n",
      "Tensor(\"add_4:0\", shape=(1, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Dropout trick \n",
    "\n",
    "keep_prob = tf.placeholder(\"float\")\n",
    "h_fc2_drop = tf.nn.dropout(h_fc2,keep_prob)\n",
    "print(h_fc2_drop)\n",
    "\n",
    "# Output layer\n",
    "\n",
    "W_fc3 = weight_variable([128,1], 'fc3', 'trunc') #Modified here\n",
    "b_fc3 = bias_variable([1], 'fc3')\n",
    "\n",
    "eps = tf.constant(0.00000001, shape=[1]) #Constant value added to prevent underflow (probability of having zero terms)\n",
    "y_conv = tf.nn.softmax(tf.matmul(h_fc2_drop, W_fc3) + b_fc3) + eps\n",
    "print(y_conv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'ScalarSummary_1:0' shape=() dtype=string>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Train and evaluate\n",
    "with tf.name_scope('cross_entropy'):\n",
    "    cross_entropy = -tf.reduce_sum(y_*tf.log(y_conv))\n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(y_conv, y_))\n",
    "with tf.name_scope('train'):\n",
    "    train_step = tf.train.AdamOptimizer(learning_rate).minimize(cross_entropy)\n",
    "    \n",
    "with tf.name_scope('accuracy'):\n",
    "    correct_prediction = tf.equal(tf.arg_max(y_conv,1),tf.arg_max(y_,1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "\n",
    "tf.scalar_summary('cost', cost)\n",
    "tf.scalar_summary('accuracy', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Merging all summaries and initializing all of the variables\n",
    "summary_op = tf.merge_all_summaries()\n",
    "init = tf.initialize_all_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "Input to reshape is a tensor with 6000 values, but the requested shape has 30\n\t [[Node: Reshape = Reshape[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](_recv_input/Placeholder_1_0/_3, Reshape/shape)]]\n\t [[Node: Reshape_2/_5 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_35_Reshape_2\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\nCaused by op 'Reshape', defined at:\n  File \"/usr/lib/python3.4/runpy.py\", line 170, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.4/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/gomez/Documents/virtual/lib/python3.4/site-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/home/gomez/Documents/virtual/lib/python3.4/site-packages/traitlets/config/application.py\", line 596, in launch_instance\n    app.start()\n  File \"/home/gomez/Documents/virtual/lib/python3.4/site-packages/ipykernel/kernelapp.py\", line 442, in start\n    ioloop.IOLoop.instance().start()\n  File \"/home/gomez/Documents/virtual/lib/python3.4/site-packages/zmq/eventloop/ioloop.py\", line 162, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/gomez/Documents/virtual/lib/python3.4/site-packages/tornado/ioloop.py\", line 827, in start\n    self._run_callback(callback)\n  File \"/home/gomez/Documents/virtual/lib/python3.4/site-packages/tornado/ioloop.py\", line 600, in _run_callback\n    ret = callback()\n  File \"/home/gomez/Documents/virtual/lib/python3.4/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/gomez/Documents/virtual/lib/python3.4/site-packages/ipykernel/kernelbase.py\", line 258, in enter_eventloop\n    self.eventloop(self)\n  File \"/home/gomez/Documents/virtual/lib/python3.4/site-packages/ipykernel/eventloops.py\", line 164, in loop_tk\n    kernel.timer.start()\n  File \"/home/gomez/Documents/virtual/lib/python3.4/site-packages/ipykernel/eventloops.py\", line 161, in start\n    self.app.mainloop()\n  File \"/usr/lib/python3.4/tkinter/__init__.py\", line 1072, in mainloop\n    self.tk.mainloop(n)\n  File \"/usr/lib/python3.4/tkinter/__init__.py\", line 1490, in __call__\n    return self.func(*args)\n  File \"/usr/lib/python3.4/tkinter/__init__.py\", line 535, in callit\n    func(*args)\n  File \"/home/gomez/Documents/virtual/lib/python3.4/site-packages/ipykernel/eventloops.py\", line 156, in on_timer\n    self.func()\n  File \"/home/gomez/Documents/virtual/lib/python3.4/site-packages/ipykernel/kernelbase.py\", line 291, in do_one_iteration\n    stream.flush(zmq.POLLIN, 1)\n  File \"/home/gomez/Documents/virtual/lib/python3.4/site-packages/zmq/eventloop/zmqstream.py\", line 352, in flush\n    self._handle_recv()\n  File \"/home/gomez/Documents/virtual/lib/python3.4/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/gomez/Documents/virtual/lib/python3.4/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/gomez/Documents/virtual/lib/python3.4/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/gomez/Documents/virtual/lib/python3.4/site-packages/ipykernel/kernelbase.py\", line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/gomez/Documents/virtual/lib/python3.4/site-packages/ipykernel/kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/gomez/Documents/virtual/lib/python3.4/site-packages/ipykernel/kernelbase.py\", line 391, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/gomez/Documents/virtual/lib/python3.4/site-packages/ipykernel/ipkernel.py\", line 199, in do_execute\n    shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/gomez/Documents/virtual/lib/python3.4/site-packages/IPython/core/interactiveshell.py\", line 2723, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/gomez/Documents/virtual/lib/python3.4/site-packages/IPython/core/interactiveshell.py\", line 2825, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/gomez/Documents/virtual/lib/python3.4/site-packages/IPython/core/interactiveshell.py\", line 2885, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-7-acfb8eb1a67e>\", line 6, in <module>\n    x_data = tf.reshape(x, [1,shpeData,1]) #Image converted in 3d\n  File \"/home/gomez/Documents/virtual/lib/python3.4/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 1750, in reshape\n    name=name)\n  File \"/home/gomez/Documents/virtual/lib/python3.4/site-packages/tensorflow/python/framework/op_def_library.py\", line 703, in apply_op\n    op_def=op_def)\n  File \"/home/gomez/Documents/virtual/lib/python3.4/site-packages/tensorflow/python/framework/ops.py\", line 2310, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/home/gomez/Documents/virtual/lib/python3.4/site-packages/tensorflow/python/framework/ops.py\", line 1232, in __init__\n    self._traceback = _extract_stack()\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m/home/gomez/Documents/virtual/lib/python3.4/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m    729\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 730\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    731\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/gomez/Documents/virtual/lib/python3.4/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m    711\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 712\u001b[1;33m                                  status, run_metadata)\n\u001b[0m\u001b[0;32m    713\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/lib/python3.4/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, type, value, traceback)\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m                 \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     67\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/gomez/Documents/virtual/lib/python3.4/site-packages/tensorflow/python/framework/errors.py\u001b[0m in \u001b[0;36mraise_exception_on_not_ok_status\u001b[1;34m()\u001b[0m\n\u001b[0;32m    449\u001b[0m           \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpywrap_tensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 450\u001b[1;33m           pywrap_tensorflow.TF_GetCode(status))\n\u001b[0m\u001b[0;32m    451\u001b[0m   \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Input to reshape is a tensor with 6000 values, but the requested shape has 30\n\t [[Node: Reshape = Reshape[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](_recv_input/Placeholder_1_0/_3, Reshape/shape)]]\n\t [[Node: Reshape_2/_5 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_35_Reshape_2\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-87dbe7d441ca>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minit\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[1;33m[\u001b[0m\u001b[0mtest_res1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtest_res2\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrshp_h_pool1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh_pool2_flat\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mbatch_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mbatch_y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mbatch_x\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;31m#, keep_prob:drop_out_prob})\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_res1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtest_res2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/gomez/Documents/virtual/lib/python3.4/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    380\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    381\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 382\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    383\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    384\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/gomez/Documents/virtual/lib/python3.4/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    653\u001b[0m     \u001b[0mmovers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_with_movers\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeed_dict_string\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_map\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    654\u001b[0m     results = self._do_run(handle, target_list, unique_fetches,\n\u001b[1;32m--> 655\u001b[1;33m                            feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[0;32m    656\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    657\u001b[0m     \u001b[1;31m# User may have fetched the same tensor multiple times, but we\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/gomez/Documents/virtual/lib/python3.4/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    721\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    722\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[1;32m--> 723\u001b[1;33m                            target_list, options, run_metadata)\n\u001b[0m\u001b[0;32m    724\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    725\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[1;32m/home/gomez/Documents/virtual/lib/python3.4/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m    741\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    742\u001b[0m           \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 743\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    744\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    745\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Input to reshape is a tensor with 6000 values, but the requested shape has 30\n\t [[Node: Reshape = Reshape[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](_recv_input/Placeholder_1_0/_3, Reshape/shape)]]\n\t [[Node: Reshape_2/_5 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_35_Reshape_2\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\nCaused by op 'Reshape', defined at:\n  File \"/usr/lib/python3.4/runpy.py\", line 170, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.4/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/gomez/Documents/virtual/lib/python3.4/site-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/home/gomez/Documents/virtual/lib/python3.4/site-packages/traitlets/config/application.py\", line 596, in launch_instance\n    app.start()\n  File \"/home/gomez/Documents/virtual/lib/python3.4/site-packages/ipykernel/kernelapp.py\", line 442, in start\n    ioloop.IOLoop.instance().start()\n  File \"/home/gomez/Documents/virtual/lib/python3.4/site-packages/zmq/eventloop/ioloop.py\", line 162, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/gomez/Documents/virtual/lib/python3.4/site-packages/tornado/ioloop.py\", line 827, in start\n    self._run_callback(callback)\n  File \"/home/gomez/Documents/virtual/lib/python3.4/site-packages/tornado/ioloop.py\", line 600, in _run_callback\n    ret = callback()\n  File \"/home/gomez/Documents/virtual/lib/python3.4/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/gomez/Documents/virtual/lib/python3.4/site-packages/ipykernel/kernelbase.py\", line 258, in enter_eventloop\n    self.eventloop(self)\n  File \"/home/gomez/Documents/virtual/lib/python3.4/site-packages/ipykernel/eventloops.py\", line 164, in loop_tk\n    kernel.timer.start()\n  File \"/home/gomez/Documents/virtual/lib/python3.4/site-packages/ipykernel/eventloops.py\", line 161, in start\n    self.app.mainloop()\n  File \"/usr/lib/python3.4/tkinter/__init__.py\", line 1072, in mainloop\n    self.tk.mainloop(n)\n  File \"/usr/lib/python3.4/tkinter/__init__.py\", line 1490, in __call__\n    return self.func(*args)\n  File \"/usr/lib/python3.4/tkinter/__init__.py\", line 535, in callit\n    func(*args)\n  File \"/home/gomez/Documents/virtual/lib/python3.4/site-packages/ipykernel/eventloops.py\", line 156, in on_timer\n    self.func()\n  File \"/home/gomez/Documents/virtual/lib/python3.4/site-packages/ipykernel/kernelbase.py\", line 291, in do_one_iteration\n    stream.flush(zmq.POLLIN, 1)\n  File \"/home/gomez/Documents/virtual/lib/python3.4/site-packages/zmq/eventloop/zmqstream.py\", line 352, in flush\n    self._handle_recv()\n  File \"/home/gomez/Documents/virtual/lib/python3.4/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/gomez/Documents/virtual/lib/python3.4/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/gomez/Documents/virtual/lib/python3.4/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/gomez/Documents/virtual/lib/python3.4/site-packages/ipykernel/kernelbase.py\", line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/gomez/Documents/virtual/lib/python3.4/site-packages/ipykernel/kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/gomez/Documents/virtual/lib/python3.4/site-packages/ipykernel/kernelbase.py\", line 391, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/gomez/Documents/virtual/lib/python3.4/site-packages/ipykernel/ipkernel.py\", line 199, in do_execute\n    shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/gomez/Documents/virtual/lib/python3.4/site-packages/IPython/core/interactiveshell.py\", line 2723, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/gomez/Documents/virtual/lib/python3.4/site-packages/IPython/core/interactiveshell.py\", line 2825, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/gomez/Documents/virtual/lib/python3.4/site-packages/IPython/core/interactiveshell.py\", line 2885, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-7-acfb8eb1a67e>\", line 6, in <module>\n    x_data = tf.reshape(x, [1,shpeData,1]) #Image converted in 3d\n  File \"/home/gomez/Documents/virtual/lib/python3.4/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 1750, in reshape\n    name=name)\n  File \"/home/gomez/Documents/virtual/lib/python3.4/site-packages/tensorflow/python/framework/op_def_library.py\", line 703, in apply_op\n    op_def=op_def)\n  File \"/home/gomez/Documents/virtual/lib/python3.4/site-packages/tensorflow/python/framework/ops.py\", line 2310, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/home/gomez/Documents/virtual/lib/python3.4/site-packages/tensorflow/python/framework/ops.py\", line 1232, in __init__\n    self._traceback = _extract_stack()\n"
     ]
    }
   ],
   "source": [
    "#Test\n",
    "\n",
    "batch_x = data.next_batch(train_data,0,200)\n",
    "batch_y = data.next_batch(train_labels,0,200)\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    [test_res1,test_res2] = sess.run([rshp_h_pool1, h_pool2_flat], feed_dict={x:batch_x, y_:batch_y, batch_size:batch_x.shape[0]})#, keep_prob:drop_out_prob})\n",
    "    \n",
    "print(test_res1.shape,test_res2.shape)\n",
    "#print('use just to test size of each layer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Solution for the problem: Debugging\n",
    "----------\n",
    "Check the data initially after the max pooling, if the problem is not found then look from the beginning\n",
    "\n",
    "--------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    writer = tf.train.SummaryWriter(tb_logs_path,graph=tf.get_default_graph())    \n",
    "    #Data used to plot the accuracy per each 20 steps\n",
    "    x_iter = np.array([])\n",
    "    y_acc = np.array([])\n",
    "    max_acc_test = [0,0]\n",
    "    #Data used in order to do the batching according to the size of the training_data\n",
    "    # 1. Batch_size will be of 200 (from 2975 training sets)\n",
    "    batch_size = 89\n",
    "    # 2. Rounds will be 10000 to start.\n",
    "    rounds = 10000\n",
    "    # The new data\n",
    "    for step in range(rounds):\n",
    "        #The batches used to train the data\n",
    "        batch_x = data.next_batch(train_data,step*batch_size,batch_size)\n",
    "        batch_y = data.next_batch(train_labels,step*batch_size,batch_size)\n",
    "        _, summary = sess.run([train_step,summary_op], feed_dict={x:batch_x, y_:batch_y, keep_prob: drop_out_prob})\n",
    "        writer.add_summary(summary, step)\n",
    "        '''This probably wont work because of the fixed numbers '''\n",
    "        if step % display_step == 0: \n",
    "            #Calculates batch accuracy\n",
    "            train_acc, loss = sess.run([accuracy, cost], feed_dict={x:batch_x, y_:batch_y, keep_prob: drop_out_prob})\n",
    "            print(' Iteration: ' + str(step) + ' , loss: ' + '{:.6f}'.format(loss) + ' Accuracy: ' + '{:.6f}'.format(train_acc))\n",
    "        if step % (display_step * 5) == 0:\n",
    "            #Calculates accuracy in test\n",
    "            test_acc = sess.run(accuracy, feed_dict={x:dataTest, y_:labelsTest, keep_prob:drop_out_prob})\n",
    "            print(\"test_acc\",test_acc)\n",
    "            if(max_acc_test[1]<test_acc):\n",
    "                max_acc_test[:] = [step,test_acc]\n",
    "            y_acc = np.append(y_acc,test_acc)\n",
    "            x_iter= np.append(x_iter,step)\n",
    "            \n",
    "    print('Optimization Finished')\n",
    "    test_acc = sess.run(accuracy, feed_dict={x:dataTest, y_:labelsTest, keep_prob:drop_out_prob})\n",
    "    print('And final test accuracy is:',test_acc)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('maximum accuracy obtained is', max_acc_test[1], 'in iteration', max_acc_test[0])\n",
    "plt.plot(x_iter,y_acc)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
